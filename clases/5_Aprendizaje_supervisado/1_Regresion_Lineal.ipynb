{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "pvIFU-3M1tJ1",
      "metadata": {
        "id": "pvIFU-3M1tJ1"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LinaMariaCastro/curso-ia-para-economia/blob/main/clases/5_Aprendizaje_supervisado/1_Regresion_Lineal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5iiwfbXCQv5D",
      "metadata": {
        "id": "5iiwfbXCQv5D"
      },
      "source": [
        "# **Inteligencia Artificial con Aplicaciones en Econom√≠a I**\n",
        "\n",
        "- üë©‚Äçüè´ **Profesora:** [Lina Mar√≠a Castro](https://www.linkedin.com/in/lina-maria-castro)  \n",
        "- üìß **Email:** [lmcastroco@gmail.com](mailto:lmcastroco@gmail.com)  \n",
        "- üéì **Universidad:** Universidad Externado de Colombia - Facultad de Econom√≠a"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "m7Kx2M9a1gri",
      "metadata": {
        "id": "m7Kx2M9a1gri"
      },
      "source": [
        "# üìà **Regresi√≥n Lineal - De la Econometr√≠a al Machine Learning**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "B4VItOmL1grn",
      "metadata": {
        "id": "B4VItOmL1grn"
      },
      "source": [
        "**Objetivos de Aprendizaje**\n",
        "\n",
        "Al finalizar este notebook, ser√°s capaz de:\n",
        "\n",
        "1.  **Diferenciar** entre el objetivo de **inferencia** (propio de la econometr√≠a cl√°sica) y el de **predicci√≥n** (central en machine learning).\n",
        "2.  **Implementar** la divisi√≥n de datos en conjuntos de **entrenamiento (train)** y **prueba (test)** como pilar fundamental para la evaluaci√≥n de modelos.\n",
        "3.  **Entrenar** un modelo de Regresi√≥n Lineal con `statsmodels` y `scikit-learn`, interpretando los resultados desde ambas perspectivas.\n",
        "4.  **Evaluar** el desempe√±o predictivo de un modelo utilizando m√©tricas como la Ra√≠z del Error Cuadr√°tico Medio (RMSE) y el R-cuadrado sobre datos no vistos."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "HyCOcA_XKEgn",
      "metadata": {
        "id": "HyCOcA_XKEgn"
      },
      "source": [
        "* **Inferencia estad√≠stica:** permite deducir informaci√≥n sobre una poblaci√≥n completa bas√°ndonos en el an√°lisis de una muestra representativa de la misma. En lugar de analizar cada elemento de la poblaci√≥n, lo cual puede ser costoso o incluso imposible, la inferencia estad√≠stica nos permite extraer conclusiones generales con un cierto grado de confianza."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "IMyGU03d1gro",
      "metadata": {
        "id": "IMyGU03d1gro"
      },
      "source": [
        "**Introducci√≥n**\n",
        "\n",
        "Imaginemos a dos profesionales:\n",
        "\n",
        "* **El Economista Investigador:** Su trabajo es entender el pasado. Quiere saber *por qu√©* la inflaci√≥n subi√≥ en el √∫ltimo a√±o. Para ello, construye un modelo econom√©trico complejo, buscando identificar las **causas** (e.g., el efecto de la tasa de cambio, el precio del petr√≥leo). Su objetivo es la **inferencia**: quiere interpretar los coeficientes y su significancia estad√≠stica para explicar un fen√≥meno.\n",
        "\n",
        "* **El Analista de Datos en un banco:** Su trabajo es anticipar qu√© puede pasar en el futuro. Necesita un modelo que le diga, con la mayor precisi√≥n posible, *cu√°l ser√°* la inflaci√≥n de los pr√≥ximos meses para que el banco pueda anticipar movimientos en las tasas de inter√©s y tomar decisiones. Su objetivo es la **predicci√≥n**. Puede que su modelo use variables menos \"explicativas\" te√≥ricamente, pero si predice bien, es un buen modelo. No le importa tanto el valor exacto de un coeficiente, sino el error de su predicci√≥n.\n",
        "\n",
        "Empezaremos con un modelo cl√°sico para *explicar* y luego lo transformaremos en una herramienta para *predecir*, introduciendo el flujo de trabajo fundamental del Machine Learning."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "p_iOpOaA1grp",
      "metadata": {
        "id": "p_iOpOaA1grp"
      },
      "source": [
        "## Importar Librer√≠as\n",
        "\n",
        "Como siempre, nuestro primer paso es cargar las herramientas que necesitaremos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "UYGwC5B31grp",
      "metadata": {
        "id": "UYGwC5B31grp"
      },
      "outputs": [],
      "source": [
        "# Librer√≠as para manipulaci√≥n y an√°lisis de datos\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Librer√≠as para visualizaci√≥n de datos\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Librer√≠as para modelamiento\n",
        "import statsmodels.api as sm  # Para el enfoque econom√©trico (inferencia)\n",
        "from sklearn.datasets import fetch_california_housing # Dataset\n",
        "from sklearn.model_selection import train_test_split # Para dividir los datos\n",
        "from sklearn.linear_model import LinearRegression # Modelo de ML (predicci√≥n)\n",
        "from sklearn.metrics import mean_squared_error, r2_score # M√©tricas de evaluaci√≥n\n",
        "\n",
        "# Pruebas de Supuestos\n",
        "from statsmodels.stats.diagnostic import het_breuschpagan, linear_reset\n",
        "from statsmodels.stats.stattools import jarque_bera\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "jHE2ZLJuEPIe",
      "metadata": {
        "id": "jHE2ZLJuEPIe"
      },
      "source": [
        "### Mejorar visualizaci√≥n de dataframes y gr√°ficos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72TA8V1fETCm",
      "metadata": {
        "id": "72TA8V1fETCm"
      },
      "outputs": [],
      "source": [
        "# Que muestre todas las columnas\n",
        "pd.options.display.max_columns = None\n",
        "# En los dataframes, mostrar los float con dos decimales\n",
        "pd.options.display.float_format = '{:,.2f}'.format\n",
        "\n",
        "# Configuraciones para una mejor visualizaci√≥n\n",
        "sns.set(style='whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (10, 6)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "IvsozHbO1grq",
      "metadata": {
        "id": "IvsozHbO1grq"
      },
      "source": [
        "## Carga y Exploraci√≥n Inicial de los Datos (EDA)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "afje5Dl5VjCx",
      "metadata": {
        "id": "afje5Dl5VjCx"
      },
      "source": [
        "**Dataset: Precios de Vivienda en California**\n",
        "\n",
        "Utilizaremos un dataset cl√°sico que busca predecir el valor mediano de las viviendas en diferentes distritos de California, basado en caracter√≠sticas de dichos distritos.\n",
        "\n",
        "**Caracter√≠sticas del Conjunto de Datos:**\n",
        "\n",
        "- N√∫mero de Instancias: 20.640\n",
        "\n",
        "- N√∫mero de Atributos: 8 atributos num√©ricos predictivos y la variable objetivo\n",
        "\n",
        "- Variable objetivo: es el valor mediano de la vivienda para los distritos de California, expresado en cientos de miles de USD.\n",
        "\n",
        "Informaci√≥n de los Atributos:\n",
        "- MedInc: ingreso mediano en el grupo de bloques (en decenas de miles de USD)\n",
        "- HouseAge: mediana de la antig√ºedad de la vivienda en el grupo de bloques (en a√±os).\n",
        "- AveRooms: n√∫mero promedio de habitaciones por hogar\n",
        "- AveBedrms: n√∫mero promedio de dormitorios por hogar\n",
        "- Population: poblaci√≥n del grupo de bloques\n",
        "- AveOccup: n√∫mero promedio de miembros del hogar\n",
        "- Latitude: latitud del grupo de bloques\n",
        "- Longitude: longitud del grupo de bloques\n",
        "\n",
        "Este conjunto de datos se deriv√≥ del censo de EE. UU. de 1990.\n",
        "\n",
        "Cada fila representa un grupo de bloques censales, el cual es la unidad geogr√°fica m√°s peque√±a para la cual la Oficina del Censo de EE. UU. publica datos de muestra (un grupo de bloques generalmente tiene una poblaci√≥n de 600 a 3.000 personas).\n",
        "\n",
        "Un hogar es un grupo de personas que residen dentro de una vivienda."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "k-j7Hgkz1grr",
      "metadata": {
        "id": "k-j7Hgkz1grr"
      },
      "outputs": [],
      "source": [
        "# Cargamos el dataset desde sklearn\n",
        "housing_bunch = fetch_california_housing()\n",
        "# print(housing_bunch.DESCR) # Descomentar para leer la descripci√≥n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-AJ1lKsaMIFf",
      "metadata": {
        "id": "-AJ1lKsaMIFf"
      },
      "outputs": [],
      "source": [
        "# Convertir a DataFrame de Pandas\n",
        "df = pd.DataFrame(housing_bunch.data, columns=housing_bunch.feature_names)\n",
        "df['MedHouseVal'] = housing_bunch.target # A√±adimos la variable objetivo\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2qSLwoXBMPZE",
      "metadata": {
        "id": "2qSLwoXBMPZE"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VD1K5ygl1grr",
      "metadata": {
        "id": "VD1K5ygl1grr"
      },
      "outputs": [],
      "source": [
        "print(\"\\nEstad√≠sticas descriptivas:\")\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9YumVvJC1grs",
      "metadata": {
        "id": "9YumVvJC1grs"
      },
      "source": [
        "### Visualizaci√≥n R√°pida"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "GPd_43L3aXJU",
      "metadata": {
        "id": "GPd_43L3aXJU"
      },
      "source": [
        "Veamos la distribuci√≥n de nuestra variable objetivo, `MedHouseVal`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9FhQgcHRahsP",
      "metadata": {
        "id": "9FhQgcHRahsP"
      },
      "outputs": [],
      "source": [
        "sns.histplot(df['MedHouseVal'], kde=True)\n",
        "plt.title('Distribuci√≥n del Valor Mediano de la Vivienda', fontsize=16)\n",
        "plt.xlabel('Valor Mediano de la Vivienda (en cientos de miles de USD)')\n",
        "plt.ylabel('Frecuencia')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tp4E1RMxKlap",
      "metadata": {
        "id": "tp4E1RMxKlap"
      },
      "source": [
        "**Observaci√≥n:** La distribuci√≥n est√° **sesgada a la derecha**. Vemos una cola larga de casas caras y una concentraci√≥n de valores en el extremo superior (~5.0) que indica que los datos fueron \"topeados\" (censurados). Este sesgo es la primera pista de que podr√≠amos tener problemas de normalidad y heteroscedasticidad."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gGxwOU6BaeJH",
      "metadata": {
        "id": "gGxwOU6BaeJH"
      },
      "source": [
        "\n",
        "Veamos la relaci√≥n entre el ingreso mediano (`MedInc`), que intuimos es la variable m√°s importante, y el valor mediano de la vivienda (`MedHouseVal`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NHy5TAFi1grt",
      "metadata": {
        "id": "NHy5TAFi1grt"
      },
      "outputs": [],
      "source": [
        "# Gr√°fico de dispersi√≥n para Ingreso vs. Valor de la Vivienda\n",
        "sns.scatterplot(x='MedInc', y='MedHouseVal', data=df, alpha=0.5)\n",
        "plt.title('Relaci√≥n entre Ingreso Mediano y Valor de la Vivienda', fontsize=16)\n",
        "plt.xlabel('Ingreso Mediano (en decenas de miles de USD)')\n",
        "plt.ylabel('Valor Mediano de la Vivienda (en cientos de miles de USD)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Awra2vQV1grt",
      "metadata": {
        "id": "Awra2vQV1grt"
      },
      "source": [
        "**Observaci√≥n:** Claramente existe una relaci√≥n lineal positiva, como esperar√≠amos."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "QHXAwjq_1gru",
      "metadata": {
        "id": "QHXAwjq_1gru"
      },
      "source": [
        "## Parte 1: El Enfoque Econom√©trico (INFERENCIA)\n",
        "\n",
        "Nuestro objetivo aqu√≠ es **explicar** el precio de la vivienda. Queremos entender la relaci√≥n entre las variables y cuantificar su significancia estad√≠stica. Usaremos la librer√≠a `statsmodels`, que nos da un *output* muy similar al de Stata o R."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tGXVd3myd1wJ",
      "metadata": {
        "id": "tGXVd3myd1wJ"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HcrgNwySMrn-",
      "metadata": {
        "id": "HcrgNwySMrn-"
      },
      "outputs": [],
      "source": [
        "# Definimos nuestras variables\n",
        "# X son las variables predictoras (independientes)\n",
        "X = df.drop('MedHouseVal', axis=1)\n",
        "X.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qtvVjl1FMvpi",
      "metadata": {
        "id": "qtvVjl1FMvpi"
      },
      "outputs": [],
      "source": [
        "# y es nuestra variable objetivo (dependiente)\n",
        "y = df['MedHouseVal']\n",
        "y.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_zXCx-sZM1Uz",
      "metadata": {
        "id": "_zXCx-sZM1Uz"
      },
      "outputs": [],
      "source": [
        "# Agregamos la constante (el intercepto)\n",
        "X_con_constante = sm.add_constant(X)\n",
        "X_con_constante.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wbmZuICvM8nm",
      "metadata": {
        "id": "wbmZuICvM8nm"
      },
      "outputs": [],
      "source": [
        "# Creamos y ajustamos el modelo de M√≠nimos Cuadrados Ordinarios (OLS)\n",
        "modelo_econometrico = sm.OLS(y, X_con_constante).fit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "n_HjKT6Q1gru",
      "metadata": {
        "id": "n_HjKT6Q1gru"
      },
      "outputs": [],
      "source": [
        "# Mostramos el resumen completo del modelo\n",
        "print(modelo_econometrico.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BWJLcs8O1grv",
      "metadata": {
        "id": "BWJLcs8O1grv"
      },
      "source": [
        "#### Interpretaci√≥n Econ√≥mica\n",
        "\n",
        "1.  **R-squared (0.606):** Nuestro modelo **explica** el 60.6% de la variabilidad en el precio de las viviendas.\n",
        "2.  **Coeficientes (coef):**\n",
        "    * **MedInc (0.4367):** Por cada aumento de $10,000 en el ingreso mediano del distrito, el valor mediano de la vivienda aumenta en `0.4367 * $100,000 = $43,670`, *ceteris paribus*.\n",
        "    * **HouseAge (0.0094):** Por cada a√±o adicional de antig√ºedad promedio de las casas, el valor aumenta en `0.0094 * $100,000 = $940`.\n",
        "3.  **P>|t| (P-values):** Casi todas nuestras variables son **estad√≠sticamente significativas** (p-valor cercano a cero), lo que nos da confianza en que estas relaciones no son producto del azar.\n",
        "\n",
        "Hasta aqu√≠, hemos hecho un buen trabajo explicando las relaciones *dentro de nuestro dataset*. Pero, ¬øqu√© tan bueno ser√≠a este modelo para predecir el precio de una casa en un distrito **nuevo**?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Ld_W2QVS1grv",
      "metadata": {
        "id": "Ld_W2QVS1grv"
      },
      "source": [
        "### Diagn√≥stico de Supuestos\n",
        "\n",
        "En el machine learning predictivo no se eval√∫a el cumplimiento de los supuestos del modelo de regresi√≥n lineal con el mismo rigor o prop√≥sito que en la econometr√≠a.\n",
        "\n",
        "La raz√≥n es la diferencia fundamental en el objetivo de cada disciplina.\n",
        "\n",
        "**El Foco de la Econometr√≠a: Inferencia**\n",
        "\n",
        "En econometr√≠a, tu objetivo principal es la inferencia causal o, como m√≠nimo, la explicaci√≥n. Quieres entender y cuantificar la relaci√≥n entre las variables. Las preguntas que buscas responder son del tipo:\n",
        "\n",
        "- Si aumentamos el salario m√≠nimo en un 1%, ¬øen cu√°nto cambiar√° el desempleo?¬øCu√°l es el efecto real de un a√±o adicional de educaci√≥n sobre el salario de una persona, manteniendo todo lo dem√°s constante?\n",
        "\n",
        "Para que puedas confiar en que los coeficientes ($\\beta$) de tu regresi√≥n representan estas relaciones de manera insesgada y eficiente, y para que los p-values y los intervalos de confianza sean v√°lidos, los supuestos del modelo son CR√çTICOS.\n",
        "\n",
        "**El Foco del Machine Learning: Predicci√≥n**\n",
        "\n",
        "En machine learning, el objetivo principal es la precisi√≥n predictiva. Tu modelo es una herramienta para hacer la mejor estimaci√≥n posible sobre datos nuevos y no vistos. La pregunta que buscas responder es:\n",
        "\n",
        "- Con los datos de un nuevo cliente, ¬øcu√°l es la probabilidad de que no pague su cr√©dito?\n",
        "- Dadas las caracter√≠sticas de una vivienda, ¬øcu√°l ser√° su precio de venta m√°s probable?\n",
        "\n",
        "En este contexto, la prueba de fuego no es si cumple con los supuestos te√≥ricos, sino qu√© tan bien funciona en la pr√°ctica. La evaluaci√≥n se centra en m√©tricas de rendimiento sobre un conjunto de prueba (test set), como la Ra√≠z del Error Cuadr√°tico Medio (RMSE) o la Precisi√≥n (Accuracy).Si un modelo de regresi√≥n lineal, a pesar de tener residuos no normales o heterocedasticidad, logra un RMSE m√°s bajo en el test set que otro modelo m√°s complejo, desde una perspectiva puramente predictiva, es el mejor modelo.\n",
        "\n",
        "**Entonces, ¬ølos Supuestos no Importan NADA en Machine Learning?**\n",
        "\n",
        "Si bien no son una barrera formal, un buen cient√≠fico de datos los utiliza como una caja de herramientas de diagn√≥stico para entender por qu√© un modelo podr√≠a no estar funcionando bien y c√≥mo mejorarlo.\n",
        "\n",
        "¬øPara qu√© sirve revisarlos?\n",
        "\n",
        "- **Mejorar el Modelo:** Si tu regresi√≥n lineal predice mal, revisar los supuestos te puede dar pistas. Por ejemplo, si un gr√°fico de residuos vs. valores predichos muestra una curva (violando el supuesto de linealidad), te sugiere que necesitas a√±adir t√©rminos polin√≥micos o usar un modelo no lineal (como un √°rbol de decisi√≥n) para capturar mejor la relaci√≥n y, por ende, mejorar tu predicci√≥n.\n",
        "- **Ingenier√≠a de Caracter√≠sticas (Feature Engineering):** Detectar heterocedasticidad (la varianza del error no es constante) podr√≠a llevarte a transformar tu variable objetivo (ej. usar $log(Precio)$ en vez de $Precio$), lo cual a menudo estabiliza la varianza y mejora el poder predictivo del modelo.\n",
        "- **Interpretabilidad:** Si adem√°s de predecir quieres tener una idea de la influencia de las variables, entonces los supuestos vuelven a ganar algo de importancia, ya que un modelo que los cumple mejor suele ser m√°s estable y sus coeficientes m√°s fiables.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2j4scdKCEpOJ",
      "metadata": {
        "id": "2j4scdKCEpOJ"
      },
      "source": [
        "Vamos a revisar 3 supuestos clave de forma visual y pr√°ctica. Primero, calculemos los residuos de nuestro `modelo_econom√©trico`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pXhNtgQ_ILtU",
      "metadata": {
        "id": "pXhNtgQ_ILtU"
      },
      "source": [
        "Encuentra mayor informaci√≥n en:\n",
        "- https://www.statsmodels.org/stable/diagnostic.html\n",
        "- https://www.statsmodels.org/dev/examples/notebooks/generated/regression_diagnostics.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lE3pISIONyou",
      "metadata": {
        "id": "lE3pISIONyou"
      },
      "outputs": [],
      "source": [
        "# Calcular los valores predichos\n",
        "fitted_values = modelo_econometrico.fittedvalues\n",
        "fitted_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6uSly0Xh1grv",
      "metadata": {
        "id": "6uSly0Xh1grv"
      },
      "outputs": [],
      "source": [
        "# Calcular los residuos\n",
        "# Residuo = Valor Observado - Valor Predicho\n",
        "residuals = modelo_econometrico.resid\n",
        "residuals"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "VFmeur_P1grw",
      "metadata": {
        "id": "VFmeur_P1grw"
      },
      "source": [
        "#### Supuesto 1: Homocedasticidad de los Residuos\n",
        "\n",
        "* **Homocedasticidad:** La varianza de los residuos debe ser constante para todos los niveles de las variables predictoras.\n",
        "\n",
        "**¬øC√≥mo lo revisamos?** Con un gr√°fico de residuos vs. valores predichos.\n",
        "\n",
        "* **¬øQu√© buscamos?** Un patr√≥n aleatorio de puntos, como una \"nube\" sin forma, centrada en cero.\n",
        "* **¬øQu√© ser√≠a una mala se√±al?** Un patr√≥n discernible, lo que indicar√≠a problemas de no linealidad o heterocedasticidad (la varianza de los errores no es constante)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RDjhSEjA1grw",
      "metadata": {
        "id": "RDjhSEjA1grw"
      },
      "outputs": [],
      "source": [
        "# Gr√°fico de Residuos vs. Valores Ajustados\n",
        "sns.scatterplot(x=fitted_values, y=residuals)\n",
        "plt.axhline(0, color='red', linestyle='--')\n",
        "plt.title('An√°lisis de Residuos: Residuos vs. Valores Ajustados', fontsize=16)\n",
        "plt.xlabel('Valores Ajustados (Predicciones)')\n",
        "plt.ylabel('Residuos')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "MvsC8aVd1grx",
      "metadata": {
        "id": "MvsC8aVd1grx"
      },
      "source": [
        "**Interpretaci√≥n:**\n",
        "Vemos un patr√≥n, indicando **heterocedasticidad**."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "265oGpsL1grx",
      "metadata": {
        "id": "265oGpsL1grx"
      },
      "source": [
        "#### Supuesto 2: Normalidad de los Residuos\n",
        "\n",
        "* **¬øQu√© significa?** Que los residuos del modelo deben seguir una distribuci√≥n normal.\n",
        "* **¬øC√≥mo lo revisamos?** Con un gr√°fico Q-Q (Quantile-Quantile) y un histograma. El gr√°fico Q-Q compara los cuantiles de nuestros residuos con los de una distribuci√≥n normal te√≥rica.\n",
        "\n",
        "* **¬øQu√© buscamos?** En el gr√°fico Q-Q, que los puntos se alineen lo m√°s cerca posible a la l√≠nea diagonal roja. En el histograma, una forma de campana de Gauss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RiFH_zQn1grx",
      "metadata": {
        "id": "RiFH_zQn1grx"
      },
      "outputs": [],
      "source": [
        "# Gr√°fico Q-Q\n",
        "sm.qqplot(residuals, line='45', fit=True)\n",
        "plt.title('Gr√°fico Q-Q de los Residuos')\n",
        "plt.show()\n",
        "\n",
        "# Histograma de los Residuos\n",
        "sns.histplot(residuals, kde=True)\n",
        "plt.title('Distribuci√≥n de los Residuos')\n",
        "plt.xlabel('Residuos')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mopnU4HN1grx",
      "metadata": {
        "id": "mopnU4HN1grx"
      },
      "source": [
        "**Interpretaci√≥n:**\n",
        "Los puntos en el gr√°fico Q-Q se desv√≠an de la l√≠nea recta en las colas (especialmente en la cola derecha). El histograma tambi√©n muestra una \"cola\" m√°s larga hacia la derecha. Esto indica que los residuos **no son perfectamente normales**. Nuestro modelo tiende a subestimar el precio de las casas m√°s caras, generando grandes errores positivos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HFxpj_XKhWLr",
      "metadata": {
        "id": "HFxpj_XKhWLr"
      },
      "outputs": [],
      "source": [
        "print(\"--- PRUEBAS FORMALES DE DIAGN√ìSTICO ---\")\n",
        "\n",
        "# 1. Test de Normalidad (Jarque-Bera)\n",
        "# H0: Los residuos son normales.\n",
        "name = ['Estad√≠stico JB', 'p-valor', 'Sesgo', 'Curtosis']\n",
        "jb_test = jarque_bera(modelo_econometrico.resid)\n",
        "print(\"Test de Normalidad (Jarque-Bera):\")\n",
        "print(list(zip(name, jb_test)))\n",
        "\n",
        "# 2. Test de Heteroscedasticidad (Breusch-Pagan)\n",
        "# H0: Los residuos son homoced√°sticos (varianza constante).\n",
        "name = ['Estad√≠stico LM', 'p-valor LM', 'Estad√≠stico F', 'p-valor F']\n",
        "bp_test = het_breuschpagan(modelo_econometrico.resid, modelo_econometrico.model.exog)\n",
        "print(\"\\nTest de Heteroscedasticidad (Breusch-Pagan):\")\n",
        "print(list(zip(name, bp_test)))\n",
        "\n",
        "# 3. Test de Linealidad (Ramsey RESET)\n",
        "# H0: El modelo tiene la forma funcional correcta (es lineal).\n",
        "reset_test = linear_reset(modelo_econometrico, power=2, test_type='fitted', use_f=True)\n",
        "print(\"\\nTest de Linealidad (Ramsey RESET):\")\n",
        "print(f\"Estad√≠stico F: {reset_test.fvalue:.4f}, p-valor: {reset_test.pvalue:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "CtWnlyspKlau",
      "metadata": {
        "id": "CtWnlyspKlau"
      },
      "source": [
        "**Interpretaci√≥n de las Pruebas Formales:**\n",
        "\n",
        "* **Normalidad (Jarque-Bera):** El `p-valor` es `0.0`. **Rechazamos** la hip√≥tesis nula de normalidad.\n",
        "* **Heteroscedasticidad (Breusch-Pagan):** El `p-valor LM` es `0.0`. **Rechazamos** la hip√≥tesis nula de homocedasticidad.\n",
        "* **Linealidad (Ramsey RESET):** El `p-valor` es `0.0`. **Rechazamos** la hip√≥tesis nula de que el modelo est√° especificado correctamente.\n",
        "\n",
        "**Conclusi√≥n:** Las pruebas formales confirman lo que vimos visualmente. El modelo est√° **mal especificado** y viola todos los supuestos clave."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9syZzkte1gry",
      "metadata": {
        "id": "9syZzkte1gry"
      },
      "source": [
        "#### Supuesto 3: Ausencia de Multicolinealidad\n",
        "\n",
        "* **¬øQu√© significa?** Que las variables predictoras no deben estar altamente correlacionadas entre s√≠. Si lo est√°n, el modelo no puede distinguir el efecto individual de cada una.\n",
        "* **¬øC√≥mo lo revisamos?** Con una matriz de correlaci√≥n y el Factor de Inflaci√≥n de la Varianza (VIF). Un VIF > 10 es generalmente considerado una se√±al de alerta."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rjpX7rls1gry",
      "metadata": {
        "id": "rjpX7rls1gry"
      },
      "outputs": [],
      "source": [
        "# Calculamos la matriz de correlaci√≥n\n",
        "corr_matrix = X.corr()\n",
        "\n",
        "# Creamos un mapa de calor para visualizarla\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap='coolwarm')\n",
        "plt.title('Matriz de Correlaci√≥n de las Variables Predictoras')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9wgja81Q1gry",
      "metadata": {
        "id": "9wgja81Q1gry"
      },
      "source": [
        "**Interpretaci√≥n:**\n",
        "- Las variables `Latitude` y `Longitude` tienen una correlaci√≥n negativa considerable (-0.92).\n",
        "- Las variables `AveRooms` y `AveBedrms` tienen una correlaci√≥n positiva alta de 0.85.\n",
        "\n",
        "* Podr√≠amos eliminar una de ellas o combinarlas en una nueva variable (reducci√≥n de dimensionalidad). Esto puede simplificar el modelo y, a veces, mejorar su capacidad de generalizaci√≥n."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d8qH72EhnZZ",
      "metadata": {
        "id": "4d8qH72EhnZZ"
      },
      "outputs": [],
      "source": [
        "# Funci√≥n para calcular el VIF. Nota: Se calcula sobre las variables X, no sobre la constante.\n",
        "def calcular_vif(X_df):\n",
        "    vif_data = pd.DataFrame()\n",
        "    vif_data[\"feature\"] = X_df.columns\n",
        "    vif_data[\"VIF\"] = [variance_inflation_factor(X_df.values, i) for i in range(X_df.shape[1])]\n",
        "    return vif_data.sort_values('VIF', ascending=False)\n",
        "\n",
        "# Calculamos el VIF para nuestras variables X\n",
        "vif_results = calcular_vif(X)\n",
        "print(\"--- Factor de Inflaci√≥n de la Varianza (VIF) ---\")\n",
        "display(vif_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ZZH_Yxb51gry",
      "metadata": {
        "id": "ZZH_Yxb51gry"
      },
      "source": [
        "## Parte 2: El Enfoque de Machine Learning (PREDICCI√ìN)\n",
        "\n",
        "Ahora cambiamos de sombrero. Ya no queremos explicar, queremos **predecir**. Para hacerlo, debemos evaluar nuestro modelo en datos que nunca ha visto."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rSSv8qsH1gry",
      "metadata": {
        "id": "rSSv8qsH1gry"
      },
      "source": [
        "### Paso clave: Dividir los Datos\n",
        "\n",
        "Imaginen que van a presentar un examen y el profesor les da las preguntas exactas para que estudien. Seguramente sacar√°n una nota perfecta, pero eso no significa que hayan aprendido el tema. Simplemente **memorizaron** las respuestas.\n",
        "\n",
        "Un modelo de machine learning puede hacer lo mismo. Si lo entrenamos y evaluamos con los mismos datos, puede \"memorizar\" las respuestas y parecer perfecto, pero fallar√° estrepitosamente cuando vea datos nuevos.\n",
        "\n",
        "La soluci√≥n es simple y poderosa: **dividimos nuestro dataset en dos partes**:\n",
        "* **Conjunto de Entrenamiento (Train set):** La mayor√≠a de los datos (usualmente 70-80%). Lo usamos para que el modelo aprenda las relaciones.\n",
        "* **Conjunto de Prueba (Test set):** El resto de los datos (20-30%). Lo mantenemos **guardado bajo llave** hasta el final. Lo usaremos para evaluar qu√© tan bien generaliza el modelo a nuevos datos."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ruxjBszjPWH",
      "metadata": {
        "id": "1ruxjBszjPWH"
      },
      "source": [
        "![Train-Test Split](https://drive.google.com/uc?id=1W8h8fB73KFlKBftFr2phxvAyzbsw8iXx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "X8LFOHPy1gry",
      "metadata": {
        "id": "X8LFOHPy1gry"
      },
      "outputs": [],
      "source": [
        "# Usamos la misma X e y que antes\n",
        "# La funci√≥n train_test_split hace la magia por nosotros\n",
        "# test_size=0.2 significa que el 20% de los datos ser√°n para prueba\n",
        "# random_state asegura que la divisi√≥n sea siempre la misma, para reproducibilidad\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Tama√±o del dataset original: {X.shape[0]} filas\")\n",
        "print(f\"Tama√±o del set de entrenamiento: {X_train.shape[0]} filas\")\n",
        "print(f\"Tama√±o del set de prueba: {X_test.shape[0]} filas\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "S54RE60l1grz",
      "metadata": {
        "id": "S54RE60l1grz"
      },
      "source": [
        "### Entrenar el Modelo\n",
        "\n",
        "Ahora usaremos `scikit-learn`, la librer√≠a comunmente utilizada para Machine Learning en Python."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0h_TSjAE1grz",
      "metadata": {
        "id": "0h_TSjAE1grz"
      },
      "outputs": [],
      "source": [
        "# 1. Creamos una instancia del modelo\n",
        "modelo_ml = LinearRegression()\n",
        "\n",
        "# 2. Entrenamos el modelo SOLAMENTE con los datos de entrenamiento\n",
        "modelo_ml.fit(X_train, y_train)\n",
        "\n",
        "# 3. Hacemos predicciones sobre el conjunto de prueba (los datos que el modelo nunca ha visto)\n",
        "predicciones = modelo_ml.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-Nvt87J-Trq2",
      "metadata": {
        "id": "-Nvt87J-Trq2"
      },
      "source": [
        "### Evaluar el Modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qGNUVGmaQFtD",
      "metadata": {
        "id": "qGNUVGmaQFtD"
      },
      "source": [
        "#### M√©tricas de desempe√±o del modelo: MSE y RMSE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "I9fJucB6P6wE",
      "metadata": {
        "id": "I9fJucB6P6wE"
      },
      "source": [
        "Tanto el MSE como el RMSE son m√©tricas que cuantifican qu√© tan \"equivocado\" est√° nuestro modelo de regresi√≥n. Ambas miden la distancia promedio entre los valores reales observados y los valores que el modelo predijo.\n",
        "\n",
        "Recuerda que la f√≥rmula base para cualquier error es:\n",
        "\n",
        "$$e_i = y_i - \\hat{y}_i$$\n",
        "\n",
        "Residuo = Valor Real - Valor Predicho\n",
        "\n",
        "**MSE: Error Cuadr√°tico Medio (Mean Squared Error)**\n",
        "\n",
        "El MSE es el punto de partida para evaluar una regresi√≥n. Su l√≥gica es:\n",
        "- Calcula cada residuo ($y_i - \\hat{y}_i$).\n",
        "- Eleva cada uno de esos residuos al cuadrado ($e_i^2$).\n",
        "- Calcula el promedio (la media) de todos esos errores al cuadrado.\n",
        "\n",
        "¬øPor qu√© elevar al cuadrado?\n",
        "- Penalizar errores grandes: Un error de 10 se convierte en 100, mientras que un error de 2 se convierte en 4. El MSE castiga de forma exponencial al modelo por estar muy equivocado en unas pocas predicciones.\n",
        "- Evitar que los errores se cancelen: Si un modelo se equivoca por +10 en una casa y por -10 en otra, el error promedio simple ser√≠a 0, lo cual es enga√±oso. Al elevar al cuadrado, ambos errores (+10 y -10) se convierten en 100, mostrando que el modelo s√≠ tiene un error significativo.\n",
        "\n",
        "$$MSE = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2$$\n",
        "\n",
        "Donde:\n",
        "\n",
        "- $n$: Es el n√∫mero total de observaciones (ej. el n√∫mero de casas en tu set de prueba).\n",
        "- $y_i$: Es el valor real de la observaci√≥n $i$.\n",
        "- $\\hat{y}_i$: Es el valor predicho por el modelo para la observaci√≥n $i$.\n",
        "\n",
        "Su principal desventaja es la interpretaci√≥n. Si est√°s prediciendo precios de casas en d√≥lares, el MSE te dar√° un error en \"d√≥lares al cuadrado\". Esto no tiene una intuici√≥n de negocio clara.\n",
        "\n",
        "**RMSE: Ra√≠z del Error Cuadr√°tico Medio (Root Mean Squared Error)**\n",
        "\n",
        "El RMSE es la soluci√≥n directa al problema de interpretaci√≥n del MSE. Es, simple y llanamente, la ra√≠z cuadrada del MSE. Devuelve la m√©trica a las unidades originales de la variable. Si tu variable $y$ est√° en d√≥lares, tu RMSE tambi√©n estar√° en d√≥lares.\n",
        "\n",
        "$$RMSE = \\sqrt{MSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}$$\n",
        "\n",
        "El RMSE es la m√©trica de error en regresi√≥n m√°s popular precisamente porque es la m√°s f√°cil de interpretar. Un RMSE de USD 72,000 se traduce directamente a una frase de negocio:\"En promedio, nuestro modelo se equivoca en USD 72,000 al predecir el precio de una vivienda.\" Esta sola frase le permite a un gerente o a un economista entender inmediatamente la precisi√≥n del modelo y decidir si es lo suficientemente bueno para sus necesidades."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Ov9ycBmx1grz",
      "metadata": {
        "id": "Ov9ycBmx1grz"
      },
      "outputs": [],
      "source": [
        "# Calculamos las m√©tricas de desempe√±o\n",
        "mse = mean_squared_error(y_test, predicciones)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, predicciones)\n",
        "\n",
        "print(f\"M√©tricas de Desempe√±o sobre el Conjunto de Prueba:\")\n",
        "print(f\"-------------------------------------------------\")\n",
        "print(f\"Error Cuadr√°tico Medio (MSE): {mse:.4f}\")\n",
        "print(f\"Ra√≠z del Error Cuadr√°tico Medio (RMSE): {rmse:.4f}\")\n",
        "print(f\"Coeficiente de Determinaci√≥n (R-cuadrado): {r2:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_hp3fR1U1grz",
      "metadata": {
        "id": "_hp3fR1U1grz"
      },
      "source": [
        "#### Interpretaci√≥n\n",
        "\n",
        "1.  **RMSE (Root Mean Squared Error):** Es la m√©trica m√°s intuitiva. Nos dice, en promedio, **cu√°nto se equivoca nuestro modelo en las unidades de la variable objetivo**.\n",
        "    * Nuestro modelo, al predecir el valor de una vivienda en un distrito que no ha visto antes, se equivoca en promedio en `0.7456 * $100,000 = $74,560`. Esto nos da una medida tangible y accionable de la precisi√≥n del modelo.\n",
        "2.  **R-cuadrado (en test):**\n",
        "    * Nuestro modelo es capaz de explicar el 57.58% de la variabilidad en los precios de las viviendas del conjunto de prueba."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XERP18NGNKz3",
      "metadata": {
        "id": "XERP18NGNKz3"
      },
      "source": [
        "#### El Pecado de No Dividir"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "LCSl3zZ-URxH",
      "metadata": {
        "id": "LCSl3zZ-URxH"
      },
      "source": [
        "Vamos a ver la diferencia entre los resultados del daset de entrenamiento y el de prueba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ldjp0TfK5xE",
      "metadata": {
        "id": "9ldjp0TfK5xE"
      },
      "outputs": [],
      "source": [
        "# 1. Creamos una instancia del modelo\n",
        "modelo_ml = LinearRegression()\n",
        "\n",
        "# 2. Entrenamos el modelo SOLAMENTE con los datos de entrenamiento\n",
        "modelo_ml.fit(X_train, y_train)\n",
        "\n",
        "# 3. Hacemos predicciones sobre el conjunto de prueba (los datos que el modelo nunca ha visto)\n",
        "predicciones_train = modelo_ml.predict(X_train)\n",
        "predicciones_test = modelo_ml.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5GgsxIH_LIb4",
      "metadata": {
        "id": "5GgsxIH_LIb4"
      },
      "outputs": [],
      "source": [
        "# Calculamos las m√©tricas de desempe√±o para entrenamiento\n",
        "mse_train = mean_squared_error(y_train, predicciones_train)\n",
        "rmse_train = np.sqrt(mse_train)\n",
        "r2_train = r2_score(y_train, predicciones_train)\n",
        "print(f\"M√©tricas de Desempe√±o sobre el Conjunto de Entranamiento:\")\n",
        "print(f\"-------------------------------------------------\")\n",
        "print(f\"Error Cuadr√°tico Medio (MSE): {mse_train:.4f}\")\n",
        "print(f\"Ra√≠z del Error Cuadr√°tico Medio (RMSE): {rmse_train:.4f}\")\n",
        "print(f\"Coeficiente de Determinaci√≥n (R-cuadrado): {r2_train:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "W0GjnP1EK8mS",
      "metadata": {
        "id": "W0GjnP1EK8mS"
      },
      "outputs": [],
      "source": [
        "# Calculamos las m√©tricas de desempe√±o para prueba\n",
        "mse_test = mean_squared_error(y_test, predicciones_test)\n",
        "rmse_test = np.sqrt(mse_test)\n",
        "r2_test = r2_score(y_test, predicciones_test)\n",
        "\n",
        "print(f\"M√©tricas de Desempe√±o sobre el Conjunto de Prueba:\")\n",
        "print(f\"-------------------------------------------------\")\n",
        "print(f\"Error Cuadr√°tico Medio (MSE): {mse:.4f}\")\n",
        "print(f\"Ra√≠z del Error Cuadr√°tico Medio (RMSE): {rmse:.4f}\")\n",
        "print(f\"Coeficiente de Determinaci√≥n (R-cuadrado): {r2:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "EZujLhQP1grz",
      "metadata": {
        "id": "EZujLhQP1grz"
      },
      "source": [
        "Ahora vamos a entrenar y evaluar el modelo con **todos** los datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ColqFaru1gr0",
      "metadata": {
        "id": "ColqFaru1gr0"
      },
      "outputs": [],
      "source": [
        "# 1. Entrenamos el modelo con TODOS los datos\n",
        "modelo_tramposo = LinearRegression()\n",
        "modelo_tramposo.fit(X, y) # Usando X e y completas\n",
        "\n",
        "# 2. \"Predecimos\" sobre los mismos datos que usamos para entrenar\n",
        "predicciones_tramposas = modelo_tramposo.predict(X)\n",
        "\n",
        "# 3. Calculamos el R-cuadrado\n",
        "r2_tramposo = r2_score(y, predicciones_tramposas)\n",
        "mse_tramposo = mean_squared_error(y, predicciones_tramposas)\n",
        "rmse_tramposo = np.sqrt(mse_tramposo)\n",
        "\n",
        "print(\"Comparaci√≥n:\")\n",
        "print(\"--------------------------\")\n",
        "print(f\"R-cuadrado evaluado en test: {r2_test:.4f}\")\n",
        "print(f\"R-cuadrado evaluado en todo el dataset: {r2_tramposo:.4f}\")\n",
        "print(\"--------------------------\")\n",
        "print(f\"RMSE evaluado en test: {rmse_test:.4f}\")\n",
        "print(f\"RMSE evaluado en todo el dataset: {rmse_tramposo:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "PxOxwTZs1gr0",
      "metadata": {
        "id": "PxOxwTZs1gr0"
      },
      "source": [
        "El R-cuadrado del `modelo_tramposo` es **ligeramente superior** al que obtuvimos de forma honesta. Aunque la diferencia no es masiva en este caso (porque la regresi√≥n lineal es un modelo simple), en modelos m√°s complejos (como los que veremos m√°s adelante), esta diferencia puede ser abismal (e.g., 0.99 vs 0.65).\n",
        "\n",
        "Esta simple demostraci√≥n es la justificaci√≥n m√°s poderosa para **SIEMPRE** dividir tus datos. El desempe√±o en el `test set` es la √∫nica medida real del valor de tu modelo predictivo."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "LjskTjAV1gr0",
      "metadata": {
        "id": "LjskTjAV1gr0"
      },
      "source": [
        "## Conclusiones\n",
        "\n",
        "* La **Econometr√≠a** (con `statsmodels`) nos ayud√≥ a **interpretar y explicar** las relaciones entre variables, enfoc√°ndonos en la significancia estad√≠stica.\n",
        "* El **Machine Learning** (con `scikit-learn`) nos introdujo a un nuevo objetivo: **predecir** sobre datos nuevos. Esto nos oblig√≥ a adoptar una nueva pr√°ctica: **la divisi√≥n de datos en entrenamiento y prueba**, y a usar nuevas m√©tricas como el **RMSE** para medir el error de predicci√≥n.\n",
        "\n",
        "El flujo de trabajo que seguimos en la segunda parte (**Cargar -> Explorar -> Dividir -> Entrenar -> Evaluar**) es la base sobre la cual construiremos todo el conocimiento del curso relativo a aprendizaje supervisado."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
